# Intel AI for Enterprise Inference


## Usage
The Usage instructions for the AI Inference as a Service Deployment Automation can be found in the [core/README.md](https://github.com/intel-innersource/applications.ai.erag.infra-automation/blob/main/core/README.md) file.
To setup, follow the step-by-step instructions provided in the `core/README.md` file.

## Contributing
If you have feature requests, encounter any bugs or have questions about the project, please [open an issue](https://github.com/intel-innersource/applications.ai.erag.infra-automation/issues) on the project's issue tracker. Provide as much detail as possible, including steps to reproduce the issue, expected behavior, and actual behavior.

## License
©2025 Intel Corporation  
Permission is granted for recipient to internally use and modify this software for purposes of benchmarking and testing on Intel architectures. 
This software is provided "AS IS" possibly with faults, bugs or errors; it is not intended for production use, and recipient uses this design at their own risk with no liability to Intel.
Intel disclaims all warranties, express or implied, including warranties of merchantability, fitness for a particular purpose, and non-infringement. 
Recipient agrees that any feedback it provides to Intel about this software is licensed to Intel for any purpose worldwide. No permission is granted to use Intel’s trademarks.
The above copyright notice and this permission notice shall be included in all copies or substantial portions of the code.
