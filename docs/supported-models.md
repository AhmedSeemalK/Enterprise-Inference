The following table lists the pre-validated models for IntelÂ® AI for Enterprise Inference.      

### Gaudi-Supported Models

| **Number** | **Model**                                                                                  |
|------------|--------------------------------------------------------------------------------------------|
| 1.         | [**llama-8b**](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)                   |
| 2.         | [**llama-70b**](https://huggingface.co/meta-llama/Llama-3.1-70B-Instruct)                |
| 4.         | [**mixtral-8x7b**](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)          |
| 5.         | [**mistral-7b**](https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.3)              |
| 9.         | [**deepseek-r1-distill-qwen-32b**](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) |
| 10.        | [**deepseek-r1-distill-llama8b**](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) |
| 11.        | [**llama3-405b**](https://huggingface.co/meta-llama/Llama-3.1-405B-Instruct)             |

### CPU-Supported Models

| **Number** | **Model**                                                                                  |
|------------|--------------------------------------------------------------------------------------------|
| 21.        | [**cpu-llama-8b**](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct)               |
| 22.        | [**cpu-deepseek-r1-distill-qwen-32b**](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) |
| 23.        | [**cpu-deepseek-r1-distill-llama8b**](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) |
